<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>python爬虫 | STAR</title><meta name="keywords" content="爬虫"><meta name="author" content="stardust,邮箱"><meta name="copyright" content="stardust"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="预备知识 ¶正则法则    字符 描述     \d 代表任意数字，就是阿拉伯数字 0-9 这些玩意。   \D 大写的就是和小写的唱反调，\d 你代表的是任意数字是吧？那么我 \D 就代表不是数字的。   \w 代表字母，数字，下划线。也就是 a-z、A-Z、0-9、_。   \W 跟 \w 唱反调，代表不是字母，不是数字，不是下划线的。   \n 代表一个换行。   \r 代表一个回车。">
<meta property="og:type" content="article">
<meta property="og:title" content="python爬虫">
<meta property="og:url" content="http://stardust14.com/2020/10/20/python%E7%88%AC%E8%99%AB/index.html">
<meta property="og:site_name" content="STAR">
<meta property="og:description" content="预备知识 ¶正则法则    字符 描述     \d 代表任意数字，就是阿拉伯数字 0-9 这些玩意。   \D 大写的就是和小写的唱反调，\d 你代表的是任意数字是吧？那么我 \D 就代表不是数字的。   \w 代表字母，数字，下划线。也就是 a-z、A-Z、0-9、_。   \W 跟 \w 唱反调，代表不是字母，不是数字，不是下划线的。   \n 代表一个换行。   \r 代表一个回车。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/stardust14/picture/img/Number2_girl.jpg">
<meta property="article:published_time" content="2020-10-20T08:29:35.000Z">
<meta property="article:modified_time" content="2020-10-20T08:29:35.000Z">
<meta property="article:author" content="stardust">
<meta property="article:tag" content="爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/stardust14/picture/img/Number2_girl.jpg"><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/stardust14/picture/img/blogstar.png"><link rel="canonical" href="http://stardust14.com/2020/10/20/python%E7%88%AC%E8%99%AB/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/stardust14.github.io/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/stardust14.github.io/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":500,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-10-20 16:29:35'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/stardust14/CDN/HexoStatic/css/newboth.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/stardust14/CDN/HexoStatic/css/hideCategory.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/stardust14/CDN/HexoStatic/css/scrollBar.css"><link rel="stylesheet" href="/css/mouse.css"><meta name="generator" content="Hexo 5.0.0"><link rel="alternate" href="/stardust14.github.io/atom.xml" title="STAR" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" data-lazy-src="/stardust14.github.io/images/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/stardust14.github.io/archives/"><div class="headline">文章</div><div class="length-num">23</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/stardust14.github.io/tags/"><div class="headline">标签</div><div class="length-num">14</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/stardust14.github.io/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/stardust14.github.io/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/stardust14.github.io/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/stardust14.github.io/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/stardust14.github.io/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 放松一下</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/stardust14.github.io/music"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/stardust14.github.io/movies"><i class="fa-fw fas fa-tags"></i><span> Movie</span></a></li><li><a class="site-page" href="/stardust14.github.io/photograph"><i class="fa-fw fa fa-globe"></i><span> Photograph</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-book"></i><span> 专栏</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/stardust14.github.io/pdf/"><i class="fa-fw fa fa-file-pdf"></i><span> pdf</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/stardust14.github.io/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/stardust14.github.io/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/stardust14.github.io/about/"><i class="fa-fw fas fa-heart"></i><span> 关于me</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/stardust14/picture/img/Number2_girl.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/stardust14.github.io/">STAR</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/stardust14.github.io/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/stardust14.github.io/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/stardust14.github.io/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/stardust14.github.io/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 放松一下</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/stardust14.github.io/music"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/stardust14.github.io/movies"><i class="fa-fw fas fa-tags"></i><span> Movie</span></a></li><li><a class="site-page" href="/stardust14.github.io/photograph"><i class="fa-fw fa fa-globe"></i><span> Photograph</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-book"></i><span> 专栏</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/stardust14.github.io/pdf/"><i class="fa-fw fa fa-file-pdf"></i><span> pdf</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/stardust14.github.io/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/stardust14.github.io/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/stardust14.github.io/about/"><i class="fa-fw fas fa-heart"></i><span> 关于me</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">python爬虫<a class="post-edit-link" href="null_posts/python爬虫.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-10-20T08:29:35.000Z" title="发表于 2020-10-20 16:29:35">2020-10-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-10-20T08:29:35.000Z" title="更新于 2020-10-20 16:29:35">2020-10-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/stardust14.github.io/categories/%E7%88%AC%E8%99%AB/">爬虫</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>30分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="python爬虫"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>预备知识</h1>
<h2 id="正则法则"><a class="header-anchor" href="#正则法则">¶</a>正则法则</h2>
<table>
<thead>
<tr>
<th style="text-align:center">字符</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>\d</code></td>
<td style="text-align:center">代表任意数字，就是阿拉伯数字 0-9 这些玩意。</td>
</tr>
<tr>
<td style="text-align:center"><code>\D</code></td>
<td style="text-align:center">大写的就是和小写的唱反调，\d 你代表的是任意数字是吧？那么我 \D 就代表不是数字的。</td>
</tr>
<tr>
<td style="text-align:center"><code>\w</code></td>
<td style="text-align:center">代表字母，数字，下划线。也就是 a-z、A-Z、0-9、_。</td>
</tr>
<tr>
<td style="text-align:center"><code>\W</code></td>
<td style="text-align:center">跟 \w 唱反调，代表不是字母，不是数字，不是下划线的。</td>
</tr>
<tr>
<td style="text-align:center"><code>\n</code></td>
<td style="text-align:center">代表一个换行。</td>
</tr>
<tr>
<td style="text-align:center"><code>\r</code></td>
<td style="text-align:center">代表一个回车。</td>
</tr>
<tr>
<td style="text-align:center"><code>\f</code></td>
<td style="text-align:center">代表换页。</td>
</tr>
<tr>
<td style="text-align:center"><code>\t</code></td>
<td style="text-align:center">代表一个 Tab 。</td>
</tr>
<tr>
<td style="text-align:center"><code>\s</code></td>
<td style="text-align:center">代表所有的空白字符，也就是上面这个：\n、\r、\t、\f。</td>
</tr>
<tr>
<td style="text-align:center"><code>\S</code></td>
<td style="text-align:center">跟 \s 唱反调，代表所有不是空白的字符。</td>
</tr>
<tr>
<td style="text-align:center"><code>\A</code></td>
<td style="text-align:center">代表字符串的开始。</td>
</tr>
<tr>
<td style="text-align:center"><code>\Z</code></td>
<td style="text-align:center">代表字符串的结束。</td>
</tr>
<tr>
<td style="text-align:center"><code>^</code></td>
<td style="text-align:center">匹配字符串开始的位置。</td>
</tr>
<tr>
<td style="text-align:center"><code>$</code></td>
<td style="text-align:center">匹配字符创结束的位置。</td>
</tr>
<tr>
<td style="text-align:center"><code>.</code></td>
<td style="text-align:center">代表所有的单个字符，除了 \n \r</td>
</tr>
<tr>
<td style="text-align:center"><code>[...]</code></td>
<td style="text-align:center">代表在 [] 范围内的字符，比如 [a-z] 就代表 a到z的字母</td>
</tr>
<tr>
<td style="text-align:center"><code>[^...]</code></td>
<td style="text-align:center">跟 […] 唱反调，代表不在 [] 范围内的字符</td>
</tr>
<tr>
<td style="text-align:center"><code>&#123;n&#125;</code></td>
<td style="text-align:center">匹配在 {n} 前面的东西，比如: o{2} 不能匹配 Bob 中的 o ，但是能匹配 food 中的两个o。</td>
</tr>
<tr>
<td style="text-align:center"><code>&#123;n,m&#125;</code></td>
<td style="text-align:center">匹配在 {n,m} 前面的东西，比如：o{1,3} 将匹配“fooooood”中的前三个o。</td>
</tr>
<tr>
<td style="text-align:center"><code>&#123;n，&#125;</code></td>
<td style="text-align:center">匹配在 {n,} 前面的东西，比如：o{2,} 不能匹配“Bob”中的“o”，但能匹配“foooood”中的所有o。</td>
</tr>
<tr>
<td style="text-align:center"><code>*</code></td>
<td style="text-align:center">和 {0,} 一个样，匹配 * 前面的 0 次或多次。 比如 zo* 能匹配“z”、“zo”以及“zoo”。</td>
</tr>
<tr>
<td style="text-align:center"><code>+</code></td>
<td style="text-align:center">和{1，} 一个样，匹配 + 前面 1 次或多次。 比如 zo+”能匹配“zo”以及“zoo”，但不能匹配“z”。</td>
</tr>
<tr>
<td style="text-align:center"><code>？</code></td>
<td style="text-align:center">和{0,1} 一个样，匹配 ？前面 0 次或 1 次。</td>
</tr>
<tr>
<td style="text-align:center"><code>a|b</code></td>
<td style="text-align:center">匹配 a 或者 b。</td>
</tr>
<tr>
<td style="text-align:center"><code>（）</code></td>
<td style="text-align:center">匹配括号里面的内容。</td>
</tr>
</tbody>
</table>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#贪婪匹配</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content=<span class="string">&#x27;hello,world.xiaoshuaib has 100 bananas&#x27;</span></span><br><span class="line">res=re.match(<span class="string">&#x27;^he.*(\d+)\s.*s$&#x27;</span>,content)</span><br><span class="line">print(res.group(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#结果是0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#非贪婪匹配，多了个？</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content=<span class="string">&#x27;hello,world.xiaoshuaib has 100 bananas&#x27;</span></span><br><span class="line">res=re.match(<span class="string">&#x27;^he.*?(\d+)\s.*s$&#x27;</span>,content)</span><br><span class="line">print(res.group(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#结果是100</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>所谓贪婪匹配就是第一段代码一个数一个数都要去匹配</p>
<p>而非贪婪是直接把 100 给匹配出来了</p>
</blockquote>
<blockquote>
<p><code>.\*？</code>:表示的就是匹配任意字符</p>
<p>.*？的 . 代表所有的单个字符，除了 \n \r</p>
</blockquote>
<p>字符串有换行:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content=<span class="string">&#x27;&#x27;&#x27;hello,world.xiaoshuaib </span></span><br><span class="line"><span class="string">has 100 bananas&#x27;&#x27;&#x27;</span></span><br><span class="line">res=re.match(<span class="string">&#x27;^he.*?(\d+)\s.*s$&#x27;</span>,content,re.S)</span><br><span class="line">print(res.group(<span class="number">1</span>))</span><br><span class="line"><span class="comment">#直接用 re.S </span></span><br></pre></td></tr></table></figure>
<p><strong>re.search</strong>:直接去扫描字符串,然后把匹配成功的<strong>第一个</strong>结果的返回</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content=<span class="string">&#x27;&#x27;&#x27;hello,world.xiaoshuaib </span></span><br><span class="line"><span class="string">has 100 bananas&#x27;&#x27;&#x27;</span></span><br><span class="line">res=re.search(<span class="string">&#x27;he.*?(\d+)\s.*s&#x27;</span>,content,re.S)</span><br><span class="line">print(res.group(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><strong>re.findall</strong>:轻松的获取所有匹配的内容</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#又在结尾多了个？</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content=<span class="string">&#x27;&#x27;&#x27;hello,world.xiaoshuaib has 100 bananas;</span></span><br><span class="line"><span class="string">hello,world.xiaoshuaib has 100 bananas;</span></span><br><span class="line"><span class="string">hello,world.xiaoshuaib has 100 bananas;</span></span><br><span class="line"><span class="string">hello,world.xiaoshuaib has 100 bananas;&#x27;&#x27;&#x27;</span></span><br><span class="line">res=re.findall(<span class="string">&#x27;he.*?(\d+)\s.*?s&#x27;</span>,content,re.S)</span><br><span class="line">print(res)</span><br></pre></td></tr></table></figure>
<p><strong>re.sub</strong>：替换字符/数字</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content=<span class="string">&#x27;&#x27;&#x27;hello,world.xiaoshuaib has 100 bananas;</span></span><br><span class="line"><span class="string">hello,world.xiaoshuaib has 100 bananas;</span></span><br><span class="line"><span class="string">hello,world.xiaoshuaib has 100 bananas;</span></span><br><span class="line"><span class="string">hello,world.xiaoshuaib has 100 bananas;&#x27;&#x27;&#x27;</span></span><br><span class="line">content=re.sub(<span class="string">&#x27;\d+&#x27;</span>,<span class="string">&#x27;250&#x27;</span>,content)</span><br><span class="line">print(content)</span><br></pre></td></tr></table></figure>
<p><strong>re.compile</strong>：主要就是把我们的匹配符封装一下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">content=<span class="string">&#x27;&#x27;&#x27;hello,world.xiaoshuaib has 100 bananas;</span></span><br><span class="line"><span class="string">hello,world.xiaoshuaib has 100 bananas;</span></span><br><span class="line"><span class="string">hello,world.xiaoshuaib has 100 bananas;</span></span><br><span class="line"><span class="string">hello,world.xiaoshuaib has 100 bananas;&#x27;&#x27;&#x27;</span></span><br><span class="line">pattern=re.compile(<span class="string">&#x27;he.*?(\d+)\s.*?s&#x27;</span>,re.S)</span><br><span class="line">res=re.findall(pattern,content)</span><br><span class="line">print(res)</span><br></pre></td></tr></table></figure>
<p>当当网爬虫：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">request_dandan</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response=requests.get(url)</span><br><span class="line">        <span class="keyword">if</span> response.status_code==<span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">    <span class="keyword">except</span> requests.RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_result</span>(<span class="params">html</span>):</span></span><br><span class="line">    pattern=re.compile(<span class="string">&#x27;&lt;li&gt;.*?list_num.*?(\d+).&lt;/div&gt;.*?&lt;img src&quot;(.*?)&quot;.*?class=&quot;name&quot;.*?title=&quot;(.*?)&quot;&gt;.*?class=&quot;star&quot;&gt;.*?class=&quot;tuijian&quot;&gt;(.*?)&lt;/span&gt;.?class=&quot;publisher_info&quot;&gt;.*?target=&quot;_blank&quot;&gt;(.*?)&lt;/a&gt;.*?class=&quot;biaosheng&quot;&gt;.*?&lt;span&gt;(.*?)&lt;/span&gt;&lt;/div&gt;.?&lt;p&gt;&lt;span\sclass=&quot;price_n&quot;&gt;￥(.*?)&lt;/span&gt;.*?&lt;/li&gt;&#x27;</span>,re.S)</span><br><span class="line">    items=re.finditer(pattern,html)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">&#x27;range&#x27;</span>:item[<span class="number">0</span>],</span><br><span class="line">            <span class="string">&#x27;iamge&#x27;</span>:item[<span class="number">1</span>],</span><br><span class="line">            <span class="string">&#x27;title&#x27;</span>:item[<span class="number">2</span>],</span><br><span class="line">            <span class="string">&#x27;recommend&#x27;</span>:item[<span class="number">3</span>],</span><br><span class="line">            <span class="string">&#x27;author&#x27;</span>:item[<span class="number">4</span>],</span><br><span class="line">            <span class="string">&#x27;times&#x27;</span>:item[<span class="number">5</span>],</span><br><span class="line">            <span class="string">&#x27;price&#x27;</span>:item[<span class="number">6</span>]</span><br><span class="line">        &#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_item_to_file</span>(<span class="params">item</span>):</span></span><br><span class="line">    print(<span class="string">&#x27;开始写入数据====&gt;&#x27;</span>+str(item))</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">&#x27;book.txt&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,encoding=<span class="string">&#x27;UTF-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(json.dumps(item,ensure_ascii=<span class="literal">False</span>)+<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">page</span>):</span></span><br><span class="line">    url=<span class="string">&#x27;http://bang.dangdang.com/books/fivestars/01.00.00.00.00.00-recent30-0-0-1-1&#x27;</span>+str(page)</span><br><span class="line">    html=request_dandan(url)</span><br><span class="line">    items=parse_result(html)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        write_item_to_file(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">26</span>):</span><br><span class="line">        main(i)</span><br></pre></td></tr></table></figure>
<h2 id="BeautifulSoup"><a class="header-anchor" href="#BeautifulSoup">¶</a>BeautifulSoup</h2>
<p>BeautifulSoup4将复杂HTML文档转换成一个复杂的树形结构，每个节点都是Python对象，所有对象可以归纳为四种:</p>
<ul>
<li>Tag</li>
<li>NavigableString</li>
<li>BeautifulSoup</li>
<li>comment</li>
</ul>
<ol>
<li>Tag</li>
</ol>
<p>标签及其内容，拿到她所找到的第一个内容</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">url=<span class="string">&quot;https://www.douban.com&quot;</span></span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># data=bytes(urllib.parse.urlencode(&#123;&#x27;name&#x27;:&#x27;eric&#x27;&#125;),encoding=&quot;utf-8&quot;)</span></span><br><span class="line">req=urllib.request.Request(url=url,headers=headers)</span><br><span class="line">reponse=urllib.request.urlopen(req)</span><br><span class="line">bs=BeautifulSoup(reponse,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line"></span><br><span class="line">print(bs.a)<span class="comment">#拿到找到第一个标签的全部信息</span></span><br></pre></td></tr></table></figure>
<ol start="2">
<li>NavigableString</li>
</ol>
<p>标签里面的内容（字符串）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(bs.title.string)<span class="comment">#拿到标签里的内容</span></span><br><span class="line">print(bs.a.attrs)  <span class="comment">#快速拿到一个标签里所有的属性，并返回一个字典</span></span><br></pre></td></tr></table></figure>
<ol start="3">
<li>BeautifulSoup</li>
</ol>
<p>表示整个文档</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(bs)</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>comment</li>
</ol>
<p>是一个特殊的NavigableString，输出的内容不包含注释符号</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(type(bs.title.string))</span><br></pre></td></tr></table></figure>
<h2 id="selenium"><a class="header-anchor" href="#selenium">¶</a>selenium</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">driver=webdriver.Chrome()<span class="comment">#创建了一个 Chrome 驱动</span></span><br><span class="line">driver.get(<span class="string">&quot;http://www.baidu.com&quot;</span>)<span class="comment">#使用 get 方法打开百度</span></span><br><span class="line"></span><br><span class="line">input=driver.find_element_by_css_selector(<span class="string">&#x27;#kw&#x27;</span>)<span class="comment">#id 定位也就是百度的搜索框所在的标签位置</span></span><br><span class="line">input.send_keys(<span class="string">&quot;hexo博客&quot;</span>)<span class="comment">#写入我们要搜索的内容</span></span><br><span class="line"></span><br><span class="line">button=driver.find_element_by_css_selector(<span class="string">&#x27;#su&#x27;</span>)<span class="comment">#相当于点击百度的百度一下按钮</span></span><br><span class="line">button.click()<span class="comment">#模拟点击一次鼠标</span></span><br></pre></td></tr></table></figure>
<p>当我们要在页面中获取一个元素的时候</p>
<p>可以使用这些方法</p>
<ul>
<li>find_element_by_id</li>
<li>find_element_by_name</li>
<li>find_element_by_xpath</li>
<li>find_element_by_link_text</li>
<li>find_element_by_partial_link_text</li>
<li>find_element_by_tag_name</li>
<li>find_element_by_class_name</li>
<li>find_element_by_css_selector</li>
</ul>
<p>想要在页面获取多个元素呢</p>
<p>就可以这样</p>
<ul>
<li>find_elements_by_name</li>
<li>find_elements_by_xpath</li>
<li>find_elements_by_link_text</li>
<li>find_elements_by_partial_link_text</li>
<li>find_elements_by_tag_name</li>
<li>find_elements_by_class_name</li>
<li>find_elements_by_css_selector</li>
</ul>
<h2 id="一些函数"><a class="header-anchor" href="#一些函数">¶</a>一些函数</h2>
<h3 id="class"><a class="header-anchor" href="#class">¶</a>class</h3>
<p>调用被封装的内容时，有两种情况：</p>
<ul>
<li>通过对象直接调用</li>
<li>通过self间接调用</li>
</ul>
<p>直接调用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">obj1 = Foo(<span class="string">&#x27;chengd&#x27;</span>, <span class="number">18</span>)</span><br><span class="line"><span class="comment"># obj1.detail()  # Python默认会将obj1传给self参数，即：obj1.detail(obj1)，所以，此时方法内部的 self ＝ obj1，即：self.name 是 chengd ；self.age 是 18</span></span><br><span class="line">print(obj1.name)</span><br><span class="line">print(obj1.age)</span><br></pre></td></tr></table></figure>
<p>间接调用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foo</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name, age</span>):</span></span><br><span class="line">    self.name = name</span><br><span class="line">    self.age = age</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">detail</span>(<span class="params">self</span>):</span></span><br><span class="line">    print(self.name)</span><br><span class="line">    print(self.age)</span><br><span class="line">  </span><br><span class="line">obj1 = Foo(<span class="string">&#x27;chengd&#x27;</span>, <span class="number">18</span>)</span><br><span class="line">obj1.detail()  <span class="comment"># Python默认会将obj1传给self参数，即：obj1.detail(obj1)，所以，此时方法内部的 self ＝ obj1，即：self.name 是 chengd ；self.age 是 18</span></span><br><span class="line">  </span><br><span class="line">obj2 = Foo(<span class="string">&#x27;python&#x27;</span>, <span class="number">99</span>)</span><br><span class="line">obj2.detail()  <span class="comment"># Python默认会将obj2传给self参数，即：obj1.detail(obj2)，所以，此时方法内部的 self ＝ obj2，即：self.name 是 python ； self.age 是 99x</span></span><br></pre></td></tr></table></figure>
<h3 id="open"><a class="header-anchor" href="#open">¶</a>open</h3>
<p>open(path, ‘-模式-‘,encoding=’UTF-8’)<br>
即open(路径+文件名, 读写模式, 编码)</p>
<p>读写模式：<br>
r ：只读<br>
r+ : 读写<br>
w ： 新建（会对原有文件进行覆盖）<br>
a ： 追加<br>
b ： 二进制文件</p>
<p>常用的模式有：<br>
“a” 以“追加”模式打开， (从 EOF 开始, 必要时创建新文件)<br>
“a+” 以”读写”模式打开<br>
“ab” 以”二进制 追加”模式打开<br>
“ab+” 以”二进制 读写”模式打开</p>
<p>“w” 以”写”的方式打开<br>
“w+” 以“读写”模式打开<br>
“wb” 以“二进制 写”模式打开<br>
“wb+” 以“二进制 读写”模式打开</p>
<p>“r+” 以”读写”模式打开<br>
“rb” 以”二进制 读”模式打开<br>
“rb+” 以”二进制 读写”模式打开</p>
<p>f.write(“hello\n”) #如果要写入字符串以外的数据,先将他转换为字符串.</p>
<h3 id="with函数"><a class="header-anchor" href="#with函数">¶</a>with函数</h3>
<p>工作原理</p>
<p><strong>紧跟with后面的语句会被求值，返回对象的__enter__()方法被调用，这个方法的返回值将被赋值给as关键字后面的变量，当with后面的代码块全部被执行完之后，将调用前面返回对象的__exit__()方法。</strong></p>
<blockquote>
<p><strong><em>enter</em>_()方法在语句体（with语句包裹起来的代码块）执行之前进入运行，<strong>exit</strong>()方法在语句体执行完毕退出后运行。</strong></p>
</blockquote>
<h3 id="write函数"><a class="header-anchor" href="#write函数">¶</a>write函数</h3>
<p>用于向文件中写入指定字符串。</p>
<h3 id="sys-stdout-write"><a class="header-anchor" href="#sys-stdout-write">¶</a>sys.stdout.write</h3>
<p>sys.stdout.write(&quot; “）的本质是print(” “, end=”&quot;)</p>
<h1>实例</h1>
<h2 id="豆瓣爬虫"><a class="header-anchor" href="#豆瓣爬虫">¶</a>豆瓣爬虫</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> urllib.request,urllib.error</span><br><span class="line"><span class="keyword">import</span> _sqlite3</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    baseurl=<span class="string">&quot;https://movie.douban.com/top250?start=&quot;</span></span><br><span class="line">    <span class="comment">#1.爬取网页</span></span><br><span class="line">    datalist=getDate(baseurl)</span><br><span class="line">    savepath=<span class="string">&quot;.\\豆瓣电影Top250.xls&quot;</span></span><br><span class="line">    <span class="comment"># 3.保存数据</span></span><br><span class="line">    saveDate(datalist,savepath)</span><br><span class="line">    <span class="comment"># askURL(baseurl)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#影片详情的规则</span></span><br><span class="line">findLink=re.compile(<span class="string">r&#x27;&lt;a href=&quot;(.*?)&quot;&gt;&#x27;</span>)       <span class="comment">#创建正则表达式对象，表示规则（字符串的模式）</span></span><br><span class="line"><span class="comment">#影片片名</span></span><br><span class="line">findTitle=re.compile(<span class="string">r&#x27;&lt;span class=&quot;title&quot;&gt;(.*)&lt;/span&gt;&#x27;</span>)</span><br><span class="line"><span class="comment">#影片的图片</span></span><br><span class="line">findImg=re.compile(<span class="string">r&#x27;&lt;img.*src=&quot;(.*?)&quot;&#x27;</span>,re.S)</span><br><span class="line"><span class="comment">#影片评分</span></span><br><span class="line">findRating=re.compile(<span class="string">r&#x27;&lt;span.*property.*&gt;(.*)&lt;/span&gt;&#x27;</span>)</span><br><span class="line"><span class="comment">#影片评价人数</span></span><br><span class="line">findPeople=re.compile(<span class="string">r&#x27;&lt;span&gt;(.*)&lt;/span&gt;&#x27;</span>)</span><br><span class="line"><span class="comment">#找到概况</span></span><br><span class="line">findInq=re.compile(<span class="string">r&#x27;&lt;span class=&quot;inq&quot;&gt;(.*)&lt;/span&gt;&#x27;</span>)</span><br><span class="line"><span class="comment">#找到影片的相关内容</span></span><br><span class="line">findBd=re.compile(<span class="string">r&#x27;&lt;p class=&quot;&quot;&gt;(.*?)&lt;/p&gt;&#x27;</span>,re.S)</span><br><span class="line"></span><br><span class="line"><span class="comment">#爬取网页</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getDate</span>(<span class="params">baseurl</span>):</span></span><br><span class="line">    datalist=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">10</span>):       <span class="comment">#调用获取页面信息的函数，10次</span></span><br><span class="line">        url=baseurl+str(i*<span class="number">25</span>)</span><br><span class="line">        html=askURL(url)        <span class="comment">#保存获取到的网页源码</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.逐一解析网页</span></span><br><span class="line">        soup=BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> soup.find_all(<span class="string">&#x27;div&#x27;</span>,class_=<span class="string">&quot;item&quot;</span>):</span><br><span class="line">            <span class="comment"># print(item)#测试查看电影item全部信息</span></span><br><span class="line">            data=[]<span class="comment">#保存一部电影的全部信息</span></span><br><span class="line">            item=str(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment">#获取到影片详情的链接</span></span><br><span class="line">            link=re.findall(findLink,item)[<span class="number">0</span>]   <span class="comment">#用re用来通过正则表达式查找指定的字符串</span></span><br><span class="line">            data.append(link)</span><br><span class="line">            <span class="comment"># print(link)</span></span><br><span class="line">            title=re.findall(findTitle,item)     <span class="comment">#影片名字</span></span><br><span class="line">            <span class="keyword">if</span>(len(title)==<span class="number">2</span>):</span><br><span class="line">                ctitle=title[<span class="number">0</span>]     <span class="comment">#添加中国名</span></span><br><span class="line">                data.append(ctitle)</span><br><span class="line">                otitle=title[<span class="number">1</span>].replace(<span class="string">&quot;/&quot;</span>,<span class="string">&quot;&quot;</span>)<span class="comment">#去掉无关的符号</span></span><br><span class="line">                data.append(otitle) <span class="comment">#添加外国名</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                data.append(title[<span class="number">0</span>])</span><br><span class="line">                data.append(<span class="string">&#x27; &#x27;</span>)        <span class="comment">#外国名留空</span></span><br><span class="line">            <span class="comment"># print(title)</span></span><br><span class="line">            img=re.findall(findImg,item)[<span class="number">0</span>]     <span class="comment">#影片图片</span></span><br><span class="line">            data.append(img)</span><br><span class="line">            <span class="comment"># print(img)</span></span><br><span class="line">            rate=re.findall(findRating,item)[<span class="number">0</span>]     <span class="comment">#评价分数</span></span><br><span class="line">            data.append(rate)</span><br><span class="line">            <span class="comment"># print(rate)</span></span><br><span class="line">            people=re.findall(findPeople,item)[<span class="number">0</span>]      <span class="comment">#评价人数</span></span><br><span class="line">            data.append(people)</span><br><span class="line">            <span class="comment"># print(people)</span></span><br><span class="line">            inp=re.findall(findInq,item)     <span class="comment">#评价概述</span></span><br><span class="line">            <span class="keyword">if</span> len(inp)!=<span class="number">0</span>:</span><br><span class="line">                inp=inp[<span class="number">0</span>].replace(<span class="string">&quot;。&quot;</span>,<span class="string">&quot;&quot;</span>)  <span class="comment">#去掉句号</span></span><br><span class="line">                data.append(inp)            <span class="comment">#添加注释</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                data.append(<span class="string">&quot; &quot;</span>)            <span class="comment">#留空</span></span><br><span class="line">            <span class="comment"># print(inp)</span></span><br><span class="line">            bd=re.findall(findBd,item)[<span class="number">0</span>]       <span class="comment">#影片相关内容</span></span><br><span class="line">            bd=re.sub(<span class="string">&#x27;&lt;br(\s+)?/&gt;(\s+)?&#x27;</span>,<span class="string">&quot; &quot;</span>,bd)   <span class="comment">#去掉br</span></span><br><span class="line">            bd=re.sub(<span class="string">&#x27;/&#x27;</span>,<span class="string">&quot; &quot;</span>,bd)       <span class="comment">#替换</span></span><br><span class="line">            data.append(bd.strip())     <span class="comment">#去掉前后的空格</span></span><br><span class="line">            <span class="comment"># print(bd)</span></span><br><span class="line">            datalist.append(data)      <span class="comment">#把处理好的一部电影信息放入datalist</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(datalist)</span></span><br><span class="line">    <span class="keyword">return</span> datalist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 得到指定一个URL的网页内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">askURL</span>(<span class="params">url</span>):</span></span><br><span class="line">    head=&#123;<span class="comment">#模拟浏览器头部信息，向豆瓣服务器发送消息</span></span><br><span class="line">        <span class="comment"># 用户代理，告诉豆瓣服务器，我们是什么类型的机器，浏览器（本质上是告诉浏览器，我么可以接收什么水平的文件内容）</span></span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36&quot;</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    request = urllib.request.Request(url,headers=head)</span><br><span class="line">    html=<span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response=urllib.request.urlopen(request)</span><br><span class="line">        html=response.read().decode(<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">        <span class="comment"># print(html)</span></span><br><span class="line">    <span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">if</span> hasattr(e,<span class="string">&quot;code&quot;</span>):</span><br><span class="line">            print(e.code)</span><br><span class="line">        <span class="keyword">if</span> hasattr(e,<span class="string">&quot;reason&quot;</span>):</span><br><span class="line">            print(e.reason)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> html</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#保存数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveDate</span>(<span class="params">datalist,savepath</span>):</span></span><br><span class="line">    book=xlwt.Workbook(encoding=<span class="string">&quot;utf-8&quot;</span>,style_compression=<span class="number">0</span>)<span class="comment">#创建workbook对象</span></span><br><span class="line">    sheet=book.add_sheet(<span class="string">&quot;豆瓣电影TOP250&quot;</span>,cell_overwrite_ok=<span class="literal">True</span>)<span class="comment">#创建工作表格</span></span><br><span class="line">    col=(<span class="string">&quot;电影详情链接&quot;</span>,<span class="string">&quot;电影中文名字&quot;</span>,<span class="string">&quot;电影外国名&quot;</span>,<span class="string">&quot;电影图片链接&quot;</span>,<span class="string">&quot;电影评分&quot;</span>,<span class="string">&quot;电影评分人数&quot;</span>,<span class="string">&quot;电影概述&quot;</span>,<span class="string">&quot;电影相关内容&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">8</span>):</span><br><span class="line">        sheet.write(<span class="number">0</span>,i,col[i])<span class="comment">#列名</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">250</span>):</span><br><span class="line">        print(<span class="string">&quot;第%d条&quot;</span>%(i+<span class="number">1</span>))</span><br><span class="line">        data=datalist[i]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">8</span>):</span><br><span class="line">            sheet.write(i+<span class="number">1</span>,j,data[j])</span><br><span class="line">    book.save(savepath)     <span class="comment">#保存</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line">    print(<span class="string">&quot;爬取完毕！&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="当当网"><a class="header-anchor" href="#当当网">¶</a>当当网</h2>
<p>获取什么信息：</p>
<ul>
<li>书名</li>
<li>作者</li>
<li>封面链接</li>
<li>价格</li>
<li>出版日期</li>
<li>评价人数</li>
<li>五星好评的次数</li>
</ul>
<div class='tip error'><p>error:部分出现乱码，还未解决，应该是生僻字<p></div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> urllib.request,urllib.error</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    baseurl=<span class="string">&quot;http://bang.dangdang.com/books/fivestars/01.00.00.00.00.00-recent30-0-0-1-&quot;</span></span><br><span class="line">    datalist = getDate(baseurl)</span><br><span class="line">    savepath=<span class="string">&quot;.\\当当网.xls&quot;</span></span><br><span class="line">    saveDate(datalist,savepath)</span><br><span class="line"><span class="comment">#书名</span></span><br><span class="line">findBook=re.compile(<span class="string">r&#x27;class=&quot;name&quot;.*?title=&quot;(.*?)&quot;&gt;&#x27;</span>,re.S)</span><br><span class="line"><span class="comment">#作者</span></span><br><span class="line">findAuthor=re.compile(<span class="string">r&#x27;&lt;a href.*?key=(.*?)&quot;&#x27;</span>,re.S)</span><br><span class="line"><span class="comment"># #封面链接</span></span><br><span class="line">findLink=re.compile(<span class="string">r&#x27;.*?&quot; src=&quot;(.*?)&quot;&#x27;</span>)</span><br><span class="line"><span class="comment"># #非会员价格</span></span><br><span class="line">findPrice1=re.compile(<span class="string">r&#x27;&lt;span class=&quot;price_r&quot;&gt;(.*?)&lt;/span&gt;&#x27;</span>)</span><br><span class="line"><span class="comment">#会员价格</span></span><br><span class="line">findPrice2=re.compile(<span class="string">r&#x27;&lt;span class=&quot;price_n&quot;&gt;(.*?)&lt;/span&gt;&#x27;</span>,re.S)</span><br><span class="line"><span class="comment">#电子书价格</span></span><br><span class="line">findPrice3=re.compile(<span class="string">r&#x27;&lt;p class=&quot;price_e&quot;&gt;.*&quot;price_n&quot;&gt;(.*?)&lt;/span&gt;&#x27;</span>,re.S)</span><br><span class="line"><span class="comment"># #出版日期</span></span><br><span class="line">findDate=re.compile(<span class="string">r&#x27;.*?_info&quot;&gt;&lt;span&gt;(.*?)&lt;/span&gt;&#x27;</span>)</span><br><span class="line"><span class="comment"># # 评价人数</span></span><br><span class="line">findPeople=re.compile(<span class="string">r&#x27;&quot;star&quot;&gt;.*?&quot;_blank&quot;&gt;(.*?)&lt;/a&gt;&#x27;</span>)</span><br><span class="line"><span class="comment"># #五星好评次数</span></span><br><span class="line">findStar=re.compile(<span class="string">r&#x27;&quot;biaosheng&quot;&gt;.*?&lt;span&gt;(.*?)&lt;/span&gt;&#x27;</span>)</span><br><span class="line"><span class="comment"># 出版社</span></span><br><span class="line">findPrint=re.compile(<span class="string">r&#x27;&quot;publisher_info&quot;&gt;.*?&quot;_blank&quot;&gt;(.*?)&lt;/a&gt;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getDate</span>(<span class="params">baseurl</span>):</span></span><br><span class="line">    datalist=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">26</span>):</span><br><span class="line">        url=baseurl+str(i)</span><br><span class="line">        html = askURL(url)  <span class="comment"># 保存获取到的网页源码</span></span><br><span class="line">        <span class="comment"># print(html)</span></span><br><span class="line"></span><br><span class="line">        soup=BeautifulSoup(html,<span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">        <span class="comment"># print(soup)</span></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> soup.find_all(<span class="string">&#x27;ul&#x27;</span>,class_=<span class="string">&quot;bang_list&quot;</span>):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> item.find_all(<span class="string">&#x27;li&#x27;</span>):</span><br><span class="line"></span><br><span class="line">                data=[]</span><br><span class="line">                item=str(i)</span><br><span class="line">                <span class="comment"># print(item)</span></span><br><span class="line"></span><br><span class="line">                book=re.findall(findBook,item)[<span class="number">0</span>]   <span class="comment">#书名</span></span><br><span class="line">                <span class="comment"># print(book)</span></span><br><span class="line">                data.append(book)</span><br><span class="line">                author=re.findall(findAuthor,item)[<span class="number">0</span>]   <span class="comment">#作者</span></span><br><span class="line">                <span class="comment"># print(author)</span></span><br><span class="line">                data.append(author)</span><br><span class="line">                img=re.findall(findLink,item)[<span class="number">0</span>]        <span class="comment">#图片链接</span></span><br><span class="line">                <span class="comment"># print(img)</span></span><br><span class="line">                data.append(img)</span><br><span class="line">                price=re.findall(findPrice1,item)[<span class="number">0</span>]        <span class="comment">#非会员书籍价格</span></span><br><span class="line">                data.append(price)</span><br><span class="line">                vipPrice=re.findall(findPrice2,item)[<span class="number">0</span>]     <span class="comment">#会员书籍价格</span></span><br><span class="line">                <span class="comment"># print(vipPrice)</span></span><br><span class="line">                data.append(vipPrice)</span><br><span class="line">                EbookPrice = re.findall(findPrice3, item)</span><br><span class="line">                <span class="comment"># print(price)</span></span><br><span class="line">                <span class="keyword">if</span> (len(EbookPrice) == <span class="number">1</span>):</span><br><span class="line">                    Eprice = EbookPrice[<span class="number">0</span>]</span><br><span class="line">                    data.append(Eprice)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># data.append(price)</span></span><br><span class="line">                    data.append(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">                <span class="comment"># print(data)</span></span><br><span class="line">                date=re.findall(findDate,item)[<span class="number">0</span>]       <span class="comment">#出版日期</span></span><br><span class="line">                data.append(date)</span><br><span class="line">                <span class="comment"># print(date)</span></span><br><span class="line">                people=re.findall(findPeople,item)[<span class="number">0</span>]      <span class="comment">#评价人数</span></span><br><span class="line">                <span class="comment"># print(people)</span></span><br><span class="line">                data.append(people)</span><br><span class="line">                star=re.findall(findStar,item)[<span class="number">0</span>]   <span class="comment">#五星好评数</span></span><br><span class="line">                <span class="comment"># print(star)</span></span><br><span class="line">                data.append(star)</span><br><span class="line">                Print=re.findall(findPrint,item)[<span class="number">0</span>]     <span class="comment">#出版社</span></span><br><span class="line">                <span class="comment"># print(Print)</span></span><br><span class="line">                data.append(Print)</span><br><span class="line">                datalist.append(data)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print(data)</span></span><br><span class="line">    <span class="keyword">return</span> datalist</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">askURL</span>(<span class="params">url</span>):</span></span><br><span class="line">    head=&#123;<span class="comment">#模拟浏览器头部信息，向豆瓣服务器发送消息</span></span><br><span class="line">        <span class="comment"># 用户代理，告诉豆瓣服务器，我们是什么类型的机器，浏览器（本质上是告诉浏览器，我么可以接收什么水平的文件内容）</span></span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36&quot;</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    request = urllib.request.Request(url,headers=head)</span><br><span class="line">    html=<span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response=urllib.request.urlopen(request)</span><br><span class="line">        html=response.read()<span class="comment">#.decode(&quot;gb2312&quot;)</span></span><br><span class="line">        <span class="comment"># print(html)</span></span><br><span class="line">    <span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">if</span> hasattr(e,<span class="string">&quot;code&quot;</span>):</span><br><span class="line">            print(e.code)</span><br><span class="line">        <span class="keyword">if</span> hasattr(e,<span class="string">&quot;reason&quot;</span>):</span><br><span class="line">            print(e.reason)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> html</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveDate</span>(<span class="params">datalist,savepath</span>):</span></span><br><span class="line">    book=xlwt.Workbook(encoding=<span class="string">&quot;utf-8&quot;</span>,style_compression=<span class="number">0</span>)</span><br><span class="line">    sheet=book.add_sheet(<span class="string">&quot;当当网书籍&quot;</span>,cell_overwrite_ok=<span class="literal">True</span>)</span><br><span class="line">    col=(<span class="string">&quot;书名&quot;</span>,<span class="string">&quot;作者&quot;</span>,<span class="string">&quot;封面链接&quot;</span>,<span class="string">&quot;非会员价格&quot;</span>,<span class="string">&quot;VIP价格&quot;</span>,<span class="string">&quot;电子书价格&quot;</span>,<span class="string">&quot;出版日期&quot;</span>,<span class="string">&quot;评价人数&quot;</span>,<span class="string">&quot;五星好评数&quot;</span>,<span class="string">&quot;出版社&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">10</span>):</span><br><span class="line">        sheet.write(<span class="number">0</span>,i,col[i])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">500</span>):</span><br><span class="line">        print(<span class="string">&quot;第%d条&quot;</span>%(i+<span class="number">1</span>))</span><br><span class="line">        data=datalist[i]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">10</span>):</span><br><span class="line">            sheet.write(i+<span class="number">1</span>,j,data[j])</span><br><span class="line">    book.save(savepath)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line">    print(<span class="string">&quot;爬取结束！&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="小说爬取成txt格式"><a class="header-anchor" href="#小说爬取成txt格式">¶</a>小说爬取成txt格式</h2>
<h3 id="一念永恒-txt"><a class="header-anchor" href="#一念永恒-txt">¶</a>一念永恒.txt</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="comment">#在类中定义的函数只有一点不同，就是第一个参数永远是实例变量self</span></span><br><span class="line"><span class="comment"># 类外面的叫函数(function)不叫方法(method)。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">download</span>(<span class="params">object</span>):</span>         <span class="comment">#用来描述具有相同的属性和方法的对象的集合</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span>     <span class="comment">#__init__方法的第一个参数永远是self，表示创建的实例本身</span></span><br><span class="line">        self.sever = <span class="string">&#x27;https://www.biqukan.com/&#x27;</span></span><br><span class="line">        self.baseurl = <span class="string">&#x27;https://www.biqukan.com/1_1094/&#x27;</span></span><br><span class="line">        self.titleNames=[]      <span class="comment">#章节的名字</span></span><br><span class="line">        self.titleUrls = []     <span class="comment">#章节的链接</span></span><br><span class="line">        self.titleNums=<span class="number">0</span>        <span class="comment">#章节数</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># def main():</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#     baseurl = &#x27;https://www.biqukan.com/1_1094/&#x27;</span></span><br><span class="line">    <span class="comment">#     # req = requests.get(url=baseurl)</span></span><br><span class="line">    <span class="comment">#     # html = req.text</span></span><br><span class="line">    <span class="comment">#     getData(self.baseurl)</span></span><br><span class="line">    <span class="comment">#     # askURL(baseurl)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getData</span>(<span class="params">self</span>):</span>      <span class="comment">#可以访问初始化self的定义值</span></span><br><span class="line">        head = &#123;  <span class="comment"># 模拟浏览器头部信息，向豆瓣服务器发送消息</span></span><br><span class="line">            <span class="comment"># 用户代理，告诉豆瓣服务器，我们是什么类型的机器，浏览器（本质上是告诉浏览器，我么可以接收什么水平的文件内容）</span></span><br><span class="line">            <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36&quot;</span></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># datalist=[]</span></span><br><span class="line">        <span class="comment"># titleNums=0</span></span><br><span class="line">        <span class="comment"># url = self.baseurl</span></span><br><span class="line">        <span class="comment"># html=askURL(url)</span></span><br><span class="line">        response = requests.get(url=self.baseurl, headers=head)</span><br><span class="line">        response.encoding = <span class="string">&quot;gb2312&quot;</span></span><br><span class="line">        html = response.text</span><br><span class="line">        bf = BeautifulSoup(html, <span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">        div=bf.find_all(<span class="string">&#x27;div&#x27;</span>,class_=<span class="string">&#x27;listmain&#x27;</span>)</span><br><span class="line">        a_bf=BeautifulSoup(str(div[<span class="number">0</span>]),<span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">        a=a_bf.find_all(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">        self.titleNums=len(a[<span class="number">13</span>:])</span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> a[<span class="number">13</span>:]:</span><br><span class="line">            self.titleNames.append(each.string)</span><br><span class="line">            self.titleUrls.append(self.sever+each.get(<span class="string">&#x27;href&#x27;</span>))</span><br><span class="line">            <span class="comment"># print(each.string,sever+each.get(&#x27;href&#x27;))</span></span><br><span class="line">        <span class="comment"># print(bf)</span></span><br><span class="line">        <span class="comment"># for item in bf.find_all()</span></span><br><span class="line">        <span class="comment"># print(self.titleNames)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">saveBook</span>(<span class="params">self,name,path,text</span>):</span>  <span class="comment">#第一个参数永远是self，实际调用写入self后面的参数即可</span></span><br><span class="line">        write_flag=<span class="literal">True</span></span><br><span class="line">        <span class="keyword">with</span> open(path,<span class="string">&#x27;a&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:  <span class="comment">#open(路径+文件名, 读写模式, 编码)</span></span><br><span class="line">            f.write(name+<span class="string">&#x27;\n&#x27;</span>)      <span class="comment">#写入path中多行，用于向文件中写入指定字符串。</span></span><br><span class="line">            f.writelines(text)      <span class="comment">#既可以传入字符串又可以传入一个字符序列,并将该字符序列写入文件</span></span><br><span class="line">            f.write(<span class="string">&#x27;\n\n&#x27;</span>)         <span class="comment">#写入回车换行</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getContent</span>(<span class="params">self,baseurl</span>):</span></span><br><span class="line">        head = &#123;  <span class="comment"># 模拟浏览器头部信息，向豆瓣服务器发送消息</span></span><br><span class="line">            <span class="comment"># 用户代理，告诉豆瓣服务器，我们是什么类型的机器，浏览器（本质上是告诉浏览器，我么可以接收什么水平的文件内容）</span></span><br><span class="line">            <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36&quot;</span></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># url = baseurl</span></span><br><span class="line">        response = requests.get(url=baseurl, headers=head)</span><br><span class="line">        response.encoding = <span class="string">&quot;gb2312&quot;</span></span><br><span class="line">        html = response.text</span><br><span class="line"></span><br><span class="line">        <span class="comment"># html = askURL(url)</span></span><br><span class="line">        bf = BeautifulSoup(html, <span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">        texts=bf.find_all(<span class="string">&#x27;div&#x27;</span>,class_=<span class="string">&#x27;showtxt&#x27;</span>)</span><br><span class="line">        texts=texts[<span class="number">0</span>].text.replace(<span class="string">&#x27;\xa0&#x27;</span>*<span class="number">8</span>,<span class="string">&#x27;\n\n&#x27;</span>)    <span class="comment">#去除空格八次，用回车换行替换</span></span><br><span class="line">        <span class="keyword">return</span> texts    <span class="comment">#返回每一章的内容</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># def askURL(url):</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#     # request = requests.get(url, headers=head)</span></span><br><span class="line">    <span class="comment">#     response = requests.get(url=url,headers=head)</span></span><br><span class="line">    <span class="comment">#     html = &quot;&quot;</span></span><br><span class="line">    <span class="comment">#     try:</span></span><br><span class="line">    <span class="comment">#         if response.status_code == 200:</span></span><br><span class="line">    <span class="comment">#             response.encoding = &quot;gb2312&quot;</span></span><br><span class="line">    <span class="comment">#             html = response.text</span></span><br><span class="line">    <span class="comment">#     except requests.RequestException:</span></span><br><span class="line">    <span class="comment">#         return None</span></span><br><span class="line">    <span class="comment">#     return html</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    d1=download()<span class="comment">#这里对类进行实例化</span></span><br><span class="line">    d1.getData()<span class="comment">#调用类中定义的方法</span></span><br><span class="line">    print(<span class="string">&#x27;小说开始下载：&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(d1.titleNums):   <span class="comment">#i循环总章节次</span></span><br><span class="line">        d1.saveBook(d1.titleNames[i],<span class="string">&#x27;白小纯.txt&#x27;</span>,d1.getContent(d1.titleUrls[i]))<span class="comment">#调用方法，没有txt就创建，设置i是调用不同的章节链接</span></span><br><span class="line">        sys.stdout.write(<span class="string">&quot;已下载:%.3f%%&quot;</span>%  float(i/d1.titleNums) + <span class="string">&#x27;\r&#x27;</span>)<span class="comment">#%格式化输出</span></span><br><span class="line">        <span class="comment">#.3f保留三位小数</span></span><br><span class="line">        sys.stdout.flush()<span class="comment">#强制其“刷新”缓冲区，刷新输出</span></span><br><span class="line">        <span class="comment"># main()</span></span><br><span class="line">    print(<span class="string">&#x27;小说下载完成&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="妹子图"><a class="header-anchor" href="#妹子图">¶</a>妹子图</h2>
<p>不完美，ip被禁！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ThreadPoolExecutor</span><br><span class="line"><span class="keyword">import</span> concurrent</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取每一页的章节链接</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPageUrls</span>():</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">2</span>):</span><br><span class="line">        baseurl=<span class="string">&#x27;https://www.mzitu.com/page/&#123;&#125;&#x27;</span>.format(i)</span><br><span class="line">        head = &#123;</span><br><span class="line">            <span class="string">&quot;DNT&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">            <span class="string">&quot;Referer&quot;</span>: <span class="string">&quot;https://www.mzitu.com/&quot;</span>,</span><br><span class="line">            <span class="comment"># 用户代理，告诉豆瓣服务器，我们是什么类型的机器，浏览器（本质上是告诉浏览器，我么可以接收什么水平的文件内容）</span></span><br><span class="line">            <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        response=requests.get(url=baseurl,headers=head,)</span><br><span class="line">        response.encoding=<span class="string">&quot;utf-8&quot;</span></span><br><span class="line">        html=response.text</span><br><span class="line">        soup=BeautifulSoup(html,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">        list=soup.find(class_=<span class="string">&#x27;postlist&#x27;</span>).find_all(<span class="string">&#x27;li&#x27;</span>)</span><br><span class="line">        urls=[]</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> list:</span><br><span class="line">            url=item.find(<span class="string">&#x27;span&#x27;</span>).find(<span class="string">&#x27;a&#x27;</span>).get(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">            <span class="comment"># print(&#x27;页面链接：%s&#x27;%url)</span></span><br><span class="line">            urls.append(url)</span><br><span class="line">    <span class="keyword">return</span> urls</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取每一页的链接地址，并下载</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPages</span>(<span class="params">url</span>):</span></span><br><span class="line">    head = &#123;</span><br><span class="line">        <span class="string">&quot;DNT&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Referer&quot;</span>: <span class="string">&quot;https://www.mzitu.com/&quot;</span>,</span><br><span class="line">        <span class="comment"># 用户代理，告诉豆瓣服务器，我们是什么类型的机器，浏览器（本质上是告诉浏览器，我么可以接收什么水平的文件内容）</span></span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.get(url=url, headers=head)</span><br><span class="line">    response.encoding = <span class="string">&quot;utf-8&quot;</span></span><br><span class="line">    html = response.text</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    total = soup.find(class_=<span class="string">&#x27;pagenavi&#x27;</span>).find_all(<span class="string">&#x27;a&#x27;</span>)[<span class="number">-2</span>].find(<span class="string">&#x27;span&#x27;</span>).string</span><br><span class="line">    title = soup.find(<span class="string">&#x27;h2&#x27;</span>).string</span><br><span class="line">    imageList=[]</span><br><span class="line">    <span class="comment"># print(total)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(int(total)):</span><br><span class="line">        <span class="comment"># html = request_page(url + &#x27;/%s&#x27; % (i + 1))</span></span><br><span class="line">        head = &#123;</span><br><span class="line">            <span class="string">&quot;DNT&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">            <span class="string">&quot;Referer&quot;</span>: <span class="string">&quot;https://www.mzitu.com/&quot;</span>,</span><br><span class="line">            <span class="comment"># 用户代理，告诉豆瓣服务器，我们是什么类型的机器，浏览器（本质上是告诉浏览器，我么可以接收什么水平的文件内容）</span></span><br><span class="line">            <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        response = requests.get(url=url + <span class="string">&#x27;/%s&#x27;</span> % (i + <span class="number">1</span>), headers=head)</span><br><span class="line">        response.encoding = <span class="string">&quot;utf-8&quot;</span></span><br><span class="line">        html = response.text</span><br><span class="line">        soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">        imgUrl = soup.find(<span class="string">&#x27;img&#x27;</span>).get(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line">        imageList.append(imgUrl)</span><br><span class="line">    <span class="comment"># print(imageList)</span></span><br><span class="line">    downloadAllImage(title,imageList)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#下载每一页的图片，并写入文件</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">downloadAllImage</span>(<span class="params">title,imagelist</span>):</span></span><br><span class="line">    os.mkdir(title)</span><br><span class="line">    j = <span class="number">1</span></span><br><span class="line">    head = &#123;</span><br><span class="line">        <span class="string">&quot;DNT&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Referer&quot;</span>: <span class="string">&quot;https://www.mzitu.com/&quot;</span>,</span><br><span class="line">        <span class="comment"># 用户代理，告诉豆瓣服务器，我们是什么类型的机器，浏览器（本质上是告诉浏览器，我么可以接收什么水平的文件内容）</span></span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 下载图片</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> imagelist:</span><br><span class="line">        filename = <span class="string">&#x27;%s/%s.jpg&#x27;</span> % (title, str(j))</span><br><span class="line">        print(<span class="string">&#x27;downloading....%s : NO.%s&#x27;</span> % (title, str(j)))</span><br><span class="line">        <span class="keyword">with</span> open(filename, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            img = requests.get(item, allow_redirects=<span class="literal">False</span>,headers=head)</span><br><span class="line">            f.write(img.content)</span><br><span class="line">        j += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_all_images</span>(<span class="params">list_page_urls</span>):</span><span class="comment">#多线程下载</span></span><br><span class="line">    <span class="comment"># 获取每一个详情妹纸</span></span><br><span class="line">    <span class="comment"># works = len(list_page_urls)</span></span><br><span class="line">    <span class="keyword">with</span> concurrent.futures.ProcessPoolExecutor(max_workers=<span class="number">5</span>) <span class="keyword">as</span> exector:</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> list_page_urls:</span><br><span class="line">            exector.submit(getPages, url)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># urls=getPageUrls()</span></span><br><span class="line">    <span class="comment"># getPages(&#x27;https://www.mzitu.com/218092&#x27;)</span></span><br><span class="line">    listPageUrls=getPageUrls()</span><br><span class="line">    <span class="comment"># print(listPageUrls)</span></span><br><span class="line">    download_all_images(listPageUrls)</span><br><span class="line">    print(<span class="string">&#x27;爬虫结束！&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>改进：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ThreadPoolExecutor</span><br><span class="line"><span class="keyword">import</span> concurrent</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPageUrls</span>():</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">2</span>):</span><br><span class="line">        baseurl=<span class="string">&#x27;https://www.mzitu.com/page/&#123;&#125;&#x27;</span>.format(i)</span><br><span class="line">        proxy=&#123;</span><br><span class="line">            <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;61.135.185.78:80&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;61.135.185.172:80&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;111.13.100.91:80&#x27;</span></span><br><span class="line">               &#125;</span><br><span class="line">        head = &#123;</span><br><span class="line">            <span class="string">&quot;DNT&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">            <span class="string">&quot;Referer&quot;</span>: <span class="string">&quot;https://www.mzitu.com/&quot;</span>,</span><br><span class="line">            <span class="comment"># 用户代理，告诉豆瓣服务器，我们是什么类型的机器，浏览器（本质上是告诉浏览器，我么可以接收什么水平的文件内容）</span></span><br><span class="line">            <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11&#x27;</span></span><br><span class="line">            <span class="comment"># &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        time.sleep(<span class="number">0.5</span>)<span class="comment">#设置访问间隔</span></span><br><span class="line">        response=requests.get(url=baseurl,headers=head,proxies=proxy)</span><br><span class="line">        response.encoding=<span class="string">&quot;utf-8&quot;</span></span><br><span class="line">        html=response.text</span><br><span class="line">        soup=BeautifulSoup(html,<span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">        list=soup.find(class_=<span class="string">&#x27;postlist&#x27;</span>).find_all(<span class="string">&#x27;li&#x27;</span>)</span><br><span class="line">        urls=[]</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> list:</span><br><span class="line">            url=item.find(<span class="string">&#x27;span&#x27;</span>).find(<span class="string">&#x27;a&#x27;</span>).get(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">            <span class="comment"># print(&#x27;页面链接：%s&#x27;%url)</span></span><br><span class="line">            urls.append(url)</span><br><span class="line">    <span class="keyword">return</span> urls</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取每一页的链接地址，并下载</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPages</span>(<span class="params">url</span>):</span></span><br><span class="line">    proxy = &#123;<span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;61.135.185.78:80&#x27;</span>&#125;</span><br><span class="line">    head = &#123;</span><br><span class="line">        <span class="string">&quot;DNT&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Referer&quot;</span>: <span class="string">&quot;https://www.mzitu.com/&quot;</span>,</span><br><span class="line">        <span class="comment"># 用户代理，告诉豆瓣服务器，我们是什么类型的机器，浏览器（本质上是告诉浏览器，我么可以接收什么水平的文件内容）</span></span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11&#x27;</span></span><br><span class="line">        <span class="comment"># &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    time.sleep(<span class="number">0.5</span>)</span><br><span class="line">    response = requests.get(url=url, headers=head,proxies=proxy)</span><br><span class="line">    response.encoding = <span class="string">&quot;utf-8&quot;</span></span><br><span class="line">    html = response.text</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">    total = soup.find(class_=<span class="string">&#x27;pagenavi&#x27;</span>).find_all(<span class="string">&#x27;a&#x27;</span>)[<span class="number">-2</span>].find(<span class="string">&#x27;span&#x27;</span>).string<span class="comment">#获取页数转换成字符串形式</span></span><br><span class="line">    title = soup.find(<span class="string">&#x27;h2&#x27;</span>).string<span class="comment">#找出标题</span></span><br><span class="line">    imageList=[]<span class="comment">#存储每一页的照片链接</span></span><br><span class="line">    <span class="comment"># print(total)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(int(total)):</span><br><span class="line">        <span class="comment"># html = request_page(url + &#x27;/%s&#x27; % (i + 1))</span></span><br><span class="line">        proxy = &#123;<span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;61.135.185.78:80&#x27;</span>&#125;</span><br><span class="line">        head = &#123;</span><br><span class="line">            <span class="string">&quot;DNT&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">            <span class="string">&quot;Referer&quot;</span>: <span class="string">&quot;https://www.mzitu.com/&quot;</span>,</span><br><span class="line">            <span class="comment"># 用户代理，告诉豆瓣服务器，我们是什么类型的机器，浏览器（本质上是告诉浏览器，我么可以接收什么水平的文件内容）</span></span><br><span class="line">            <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11&#x27;</span></span><br><span class="line">            <span class="comment">#&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">        time.sleep(<span class="number">0.5</span>)</span><br><span class="line">        response = requests.get(url=url + <span class="string">&#x27;/%s&#x27;</span> % (i + <span class="number">1</span>), headers=head,proxies=proxy)<span class="comment">#</span></span><br><span class="line">        response.encoding = <span class="string">&quot;utf-8&quot;</span></span><br><span class="line">        html = response.text</span><br><span class="line">        soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">        imgUrl = soup.find(<span class="string">&#x27;img&#x27;</span>).get(<span class="string">&#x27;src&#x27;</span>)<span class="comment">#找出每张照片的链接</span></span><br><span class="line">        imageList.append(imgUrl)</span><br><span class="line">    <span class="comment"># print(imageList)</span></span><br><span class="line">    downloadAllImage(title,imageList)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#下载每一页的图片，并写入文件</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">downloadAllImage</span>(<span class="params">title,imagelist</span>):</span></span><br><span class="line">    os.mkdir(title)</span><br><span class="line">    j = <span class="number">1</span></span><br><span class="line">    proxy = &#123;<span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;61.135.185.78:80&#x27;</span>&#125;</span><br><span class="line">    head = &#123;</span><br><span class="line">        <span class="string">&quot;DNT&quot;</span>: <span class="string">&quot;1&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Referer&quot;</span>: <span class="string">&quot;https://www.mzitu.com/&quot;</span>,</span><br><span class="line">        <span class="comment"># 用户代理，告诉豆瓣服务器，我们是什么类型的机器，浏览器（本质上是告诉浏览器，我么可以接收什么水平的文件内容）</span></span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11&#x27;</span></span><br><span class="line">        <span class="comment">#&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 下载图片</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> imagelist:</span><br><span class="line">        filename = <span class="string">&#x27;%s/%s.jpg&#x27;</span> % (title, str(j))</span><br><span class="line">        print(<span class="string">&#x27;downloading....%s : NO.%s&#x27;</span> % (title, str(j)))</span><br><span class="line">        <span class="keyword">with</span> open(filename, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:<span class="comment">#打开新建的文件，并写入图片</span></span><br><span class="line">            time.sleep(<span class="number">0.5</span>)</span><br><span class="line">            img = requests.get(item, allow_redirects=<span class="literal">False</span>,headers=head,proxies=proxy)<span class="comment">#allow_redirects=False为拒绝默认的301/302重定向</span></span><br><span class="line">            <span class="comment"># 获取二进制数据; 注意: 这里不要解码, 因为图片,视频等文件都是二进制的不是文本,不需要解码</span></span><br><span class="line">            f.write(img.content)<span class="comment">#写入图片（下载图片）</span></span><br><span class="line">        j += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#设置多线程</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_all_images</span>(<span class="params">list_page_urls</span>):</span></span><br><span class="line">    <span class="comment"># 获取每一个详情妹纸</span></span><br><span class="line">    <span class="comment"># works = len(list_page_urls)</span></span><br><span class="line">    <span class="keyword">with</span> concurrent.futures.ProcessPoolExecutor(max_workers=<span class="number">5</span>) <span class="keyword">as</span> exector:</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> list_page_urls:</span><br><span class="line">            exector.submit(getPages, url)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># urls=getPageUrls()</span></span><br><span class="line">    <span class="comment"># print(urls)</span></span><br><span class="line">    <span class="comment"># getPages(&#x27;https://www.mzitu.com/218092&#x27;)</span></span><br><span class="line">    listPageUrls=getPageUrls()</span><br><span class="line">    <span class="comment"># print(listPageUrls)</span></span><br><span class="line">    download_all_images(listPageUrls)</span><br><span class="line">    print(<span class="string">&#x27;爬虫结束！&#x27;</span>)</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:邮箱">stardust</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://stardust14.com/2020/10/20/python%E7%88%AC%E8%99%AB/">http://stardust14.com/2020/10/20/python%E7%88%AC%E8%99%AB/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://stardust14.com" target="_blank">STAR</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/stardust14.github.io/tags/%E7%88%AC%E8%99%AB/">爬虫</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/stardust14/picture/img/Number2_girl.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button button--animated"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/stardust14.github.io/" target="_blank"><img class="post-qr-code-img" data-lazy-src="/stardust14.github.io/"/></a><div class="post-qr-code-desc"></div></li><li class="reward-item"><a href="/stardust14.github.io/" target="_blank"><img class="post-qr-code-img" data-lazy-src="/stardust14.github.io/"/></a><div class="post-qr-code-desc"></div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/stardust14.github.io/2020/10/31/Linux%E7%AE%80%E5%8D%95%E7%9F%A5%E8%AF%86/"><img class="prev-cover" data-lazy-src="https://cdn.jsdelivr.net/gh/stardust14/picture/img/test013.jpg" onerror="onerror=null;src='/stardust14.github.io/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Linux简单知识</div></div></a></div><div class="next-post pull-right"><a href="/stardust14.github.io/2020/10/17/js%E5%AD%A6%E4%B9%A0/"><img class="next-cover" data-lazy-src="https://cdn.jsdelivr.net/gh/stardust14/picture/img/Number_one_gril.jpg" onerror="onerror=null;src='/stardust14.github.io/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">js学习</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">预备知识</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E6%B3%95%E5%88%99"><span class="toc-number">1.1.</span> <span class="toc-text">正则法则</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BeautifulSoup"><span class="toc-number">1.2.</span> <span class="toc-text">BeautifulSoup</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#selenium"><span class="toc-number">1.3.</span> <span class="toc-text">selenium</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E5%87%BD%E6%95%B0"><span class="toc-number">1.4.</span> <span class="toc-text">一些函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#class"><span class="toc-number">1.4.1.</span> <span class="toc-text">class</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#open"><span class="toc-number">1.4.2.</span> <span class="toc-text">open</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#with%E5%87%BD%E6%95%B0"><span class="toc-number">1.4.3.</span> <span class="toc-text">with函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#write%E5%87%BD%E6%95%B0"><span class="toc-number">1.4.4.</span> <span class="toc-text">write函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sys-stdout-write"><span class="toc-number">1.4.5.</span> <span class="toc-text">sys.stdout.write</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">实例</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B1%86%E7%93%A3%E7%88%AC%E8%99%AB"><span class="toc-number">2.1.</span> <span class="toc-text">豆瓣爬虫</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BD%93%E5%BD%93%E7%BD%91"><span class="toc-number">2.2.</span> <span class="toc-text">当当网</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E8%AF%B4%E7%88%AC%E5%8F%96%E6%88%90txt%E6%A0%BC%E5%BC%8F"><span class="toc-number">2.3.</span> <span class="toc-text">小说爬取成txt格式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E5%BF%B5%E6%B0%B8%E6%81%92-txt"><span class="toc-number">2.3.1.</span> <span class="toc-text">一念永恒.txt</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%B9%E5%AD%90%E5%9B%BE"><span class="toc-number">2.4.</span> <span class="toc-text">妹子图</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://cdn.jsdelivr.net/gh/stardust14/picture/img/Number2_girl.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By stardust</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/stardust14.github.io/js/utils.js"></script><script src="/stardust14.github.io/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/stardust14.github.io/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'HTNDsPzD87VFJzxigXr0LgQT-gzGzoHsz',
      appKey: 'rujMRAYTJMNb3muoM0nm6YCs',
      placeholder: '请留下你来过的痕迹吧~',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '//i0.hdslb.com/bfs/emote/',
      emojiMaps: {"[tv_白眼]":"c1d59f439e379ee50eef488bcb5e5378e5044ea4.png","[tv_doge]":"6ea59c827c414b4a2955fe79e0f6fd3dcd515e24.png","[tv_坏笑]":"1f0b87f731a671079842116e0991c91c2c88645a.png","[tv_难过]":"87f46748d3f142ebc6586ff58860d0e2fc8263ba.png","[tv_生气]":"26702dcafdab5e8225b43ffd23c94ac1ff932654.png","[tv_委屈]":"d04dba7b5465779e9755d2ab6f0a897b9b33bb77.png","[tv_斜眼笑]":"911f987aa8bc1bee12d52aafe62bc41ef4474e6c.png","[tv_呆]":"fe1179ebaa191569b0d31cecafe7a2cd1c951c9d.png","[tv_发怒]":"34ba3cd204d5b05fec70ce08fa9fa0dd612409ff.png","[tv_惊吓]":"0d15c7e2ee58e935adc6a7193ee042388adc22af.png","[tv_呕吐]":"9f996894a39e282ccf5e66856af49483f81870f3.png","[tv_思考]":"90cf159733e558137ed20aa04d09964436f618a1.png","[tv_微笑]":"70dc5c7b56f93eb61bddba11e28fb1d18fddcd4c.png","[tv_疑问]":"0793d949b18d7be716078349c202c15ff166f314.png","[tv_大哭]":"23269aeb35f99daee28dda129676f6e9ea87934f.png","[tv_鼓掌]":"1d21793f96ef4e6f48b23e53e3b9e42da833a0f6.png","[tv_抠鼻]":"c666f55e88d471e51bbd9fab9bb308110824a6eb.png","[tv_亲亲]":"a8111ad55953ef5e3be3327ef94eb4a39d535d06.png","[tv_调皮]":"b9c41de8e82dd7a8515ae5e3cb63e898bf245186.png","[tv_笑哭]":"1abc628f6d4f4caf9d0e7800878f4697abbc8273.png","[tv_晕]":"5443c22b4d07fb1907ccc610c8e6db254f2461b7.png","[tv_点赞]":"f85c354995bd99e28fc76c869bfe42ba6438eff4.png","[tv_害羞]":"a37683fb5642fa3ddfc7f4e5525fd13e42a2bdb1.png","[tv_睡着]":"8b196675b53af58264f383c50ad0945048290b33.png","[tv_色]":"61822c7e9aae5da76475e7892534545336b23a6f.png","[tv_吐血]":"09dd16a7aa59b77baa1155d47484409624470c77.png","[tv_无奈]":"ea8ed89ee9878f2fece2dda0ea8a5dbfe21b5751.png","[tv_再见]":"180129b8ea851044ce71caf55cc8ce44bd4a4fc8.png","[tv_流汗]":"cead1c351ab8d79e9f369605beb90148db0fbed3.png","[tv_偷笑]":"bb690d4107620f1c15cff29509db529a73aee261.png","[tv_抓狂]":"fe31c08edad661d63762b04e17b8d5ae3c71a757.png","[tv_黑人问号]":"45821a01f51bc867da9edbaa2e070410819a95b2.png","[tv_困]":"241ee304e44c0af029adceb294399391e4737ef2.png","[tv_打脸]":"56ab10b624063e966bfcb76ea5dc4794d87dfd47.png","[tv_闭嘴]":"c9e990da7f6e93975e25fd8b70e2e290aa4086ef.png","[tv_鄙视]":"6e72339f346a692a495b123174b49e4e8e781303.png","[tv_腼腆]":"89712c0d4af73e67f89e35cbc518420380a7f6f4.png","[tv_馋]":"fc7e829b845c43c623c8b490ee3602b7f0e76a31.png","[tv_可爱]":"9e55fd9b500ac4b96613539f1ce2f9499e314ed9.png","[tv_发财]":"34db290afd2963723c6eb3c4560667db7253a21a.png","[tv_生病]":"8b0ec90e6b86771092a498c54f09fc94621c1900.png","[tv_流鼻血]":"c32d39db2737f89b904ca32700d140a9241b0767.png","[tv_尴尬]":"7cfa62dafc59798a3d3fb262d421eeeff166cfa4.png","[tv_大佬]":"093c1e2c490161aca397afc45573c877cdead616.png","[tv_流泪]":"7e71cde7858f0cd50d74b0264aa26db612a8a167.png","[tv_冷漠]":"b9cbc755c2b3ee43be07ca13de84e5b699a3f101.png","[tv_皱眉]":"72ccad6679fea0d14cce648b4d818e09b8ffea2d.png","[tv_鬼脸]":"0ffbbddf8a94d124ca2f54b360bbc04feb6bbfea.png","[tv_调侃]":"4bc022533ef31544ca0d72c12c808cf4a1cce3e3.png","[tv_目瞪口呆]":"0b8cb81a68de5d5365212c99375e7ace3e7891b7.png","[2233娘_大笑]":"16b8794be990cefa6caeba4d901b934a227ee3b8.png","[2233娘_疑问]":"0b41f509351958dbb63d472fec0132d1bd03bd14.png","[2233娘_吃惊]":"d1628c43d35b1530c0504a643ff80b6189fa0a43.png","[2233娘_汗]":"247cd9df8cdf84b18368c21e3b2dd374e84c0927.png","[2233娘_大哭]":"476a2a60f6e337b8c0697a592e0aa82781f6b33b.png","[2233娘_困惑]":"714eeb4eae0d0933b4ff08b7df788b1982f6b940.png","[2233娘_耶]":"d7178e258a0efc969b65ccc2b1322fb235f5dff4.png","[2233娘_怒]":"f31953119c51b9748016440ac0b632f779929b37.png","[2233娘_卖萌]":"ea893aa25355de95ab4f03c2dad3f0c58d0c159e.png","[2233娘_委屈]":"d9d0bf9d358af8d5761093ec66d4e3f60d963a63.png","[2233娘_郁闷]":"485203fe7100f2c8fc40b2800a18fe20b35f2f1a.png","[2233娘_第一]":"3754ee6e5985bd0bd7dfb668981f2a8733398ebd.png","[2233娘_喝水]":"695bf5429472049b52c1e0de586f8a2511195a23.png","[2233娘_吐魂]":"e999af499edf38a91ca68b1a9d2f97042c1d6734.png","[2233娘_无言]":"fdb5870f32cfaf7949e0f88a13f6feba4a48b719.png","[加油武汉]":"eb966aaa5b690d3f9308a9f936f5b5a72a7f956b.png","[口罩]":"3ad2f66b151496d2a5fb0a8ea75f32265d778dd3.png","[鸡腿]":"c7860392815d345fa69c4f00ef18d67dccfbd574.png","[微笑]":"685612eadc33f6bc233776c6241813385844f182.png","[笑]":"81edf17314cea3b48674312b4364df44d5c01f17.png","[呲牙]":"b5a5898491944a4268360f2e7a84623149672eb6.png","[OK]":"4683fd9ffc925fa6423110979d7dcac5eda297f4.png","[星星眼]":"63c9d1a31c0da745b61cdb35e0ecb28635675db2.png","[哦呼]":"362bded07ea5434886271d23fa25f5d85d8af06c.png","[嫌弃]":"de4c0783aaa60ec03de0a2b90858927bfad7154b.png","[喜欢]":"8a10a4d73a89f665feff3d46ca56e83dc68f9eb8.png","[酸了]":"92b1c8cbceea3ae0e8e32253ea414783e8ba7806.png","[大哭]":"2caafee2e5db4db72104650d87810cc2c123fc86.png","[害羞]":"9d2ec4e1fbd6cb1b4d12d2bbbdd124ccb83ddfda.png","[无语]":"44667b7d9349957e903b1b62cb91fb9b13720f04.png","[疑惑]":"b7840db4b1f9f4726b7cb23c0972720c1698d661.png","[调皮]":"8290b7308325e3179d2154327c85640af1528617.png","[喜极而泣]":"485a7e0c01c2d70707daae53bee4a9e2e31ef1ed.png","[奸笑]":"bb84906573472f0a84cebad1e9000eb6164a6f5a.png","[偷笑]":"6c49d226e76c42cd8002abc47b3112bc5a92f66a.png","[大笑]":"ca94ad1c7e6dac895eb5b33b7836b634c614d1c0.png","[阴险]":"ba8d5f8e7d136d59aab52c40fd3b8a43419eb03c.png","[捂脸]":"6921bb43f0c634870b92f4a8ad41dada94a5296d.png","[囧]":"12e41d357a9807cc80ef1e1ed258127fcc791424.png","[呆]":"33ad6000d9f9f168a0976bc60937786f239e5d8c.png","[抠鼻]":"cb89184c97e3f6d50acfd7961c313ce50360d70f.png","[惊喜]":"0afecaf3a3499479af946f29749e1a6c285b6f65.png","[惊讶]":"f8e9a59cad52ae1a19622805696a35f0a0d853f3.png","[笑哭]":"c3043ba94babf824dea03ce500d0e73763bf4f40.png","[妙啊]":"b4cb77159d58614a9b787b91b1cd22a81f383535.png","[doge]":"bba7c12aa51fed0199c241465560dfc2714c593e.png","[滑稽]":"d15121545a99ac46774f1f4465b895fe2d1411c3.png","[吃瓜]":"4191ce3c44c2b3df8fd97c33f85d3ab15f4f3c84.png ","[打call]":"431432c43da3ee5aab5b0e4f8931953e649e9975.png","[点赞]":"1a67265993913f4c35d15a6028a30724e83e7d35.png","[鼓掌]":"895d1fc616b4b6c830cf96012880818c0e1de00d.png  ","[尴尬]":"cb321684ed5ce6eacdc2699092ab8fe7679e4fda.png","[冷]":"cb0ebbd0668640f07ebfc0e03f7a18a8cd00b4ed.png","[灵魂出窍]":"43d3db7d97343c01b47e22cfabeca84b4251f35a.png","[委屈]":"d2f26cbdd6c96960320af03f5514c5b524990840.png","[傲娇]":"010540d0f61220a0db4922e4a679a1d8eca94f4e.png","[疼]":"905fd9a99ec316e353b9bd4ecd49a5f0a301eabf.png","[吓]":"9c10c5ebc7bef27ec641b8a1877674e0c65fea5d.png","[生病]":"0f25ce04ae1d7baf98650986454c634f6612cb76.png","[吐]":"06946bfe71ac48a6078a0b662181bb5cad09decc.png","[嘘声]":"e64af664d20716e090f10411496998095f62f844.png","[捂眼]":"c5c6d6982e1e53e478daae554b239f2b227b172b.png","[思考]":"cfa9b7e89e4bfe04bbcd34ccb1b0df37f4fa905c.png","[再见]":"fc510306bae26c9aec7e287cdf201ded27b065b9.png","[翻白眼]":"eba54707c7168925b18f6f8b1f48d532fe08c2b1.png","[哈欠]":"888d877729cbec444ddbd1cf4c9af155a7a06086.png","[奋斗]":"bb2060c15dba7d3fd731c35079d1617f1afe3376.png","[墨镜]":"3a03aebfc06339d86a68c2d893303b46f4b85771.png","[撇嘴]":"531863568e5668c5ac181d395508a0eeb1f0cda4.png","[难过]":"a651db36701610aa70a781fa98c07c9789b11543.png","[抓狂]":"4c87afff88c22439c45b79e9d2035d21d5622eba.png","[生气]":"3195714219c4b582a4fb02033dd1519913d0246d.png","[干杯]":"8da12d5f55a2c7e9778dcc05b40571979fe208e6.png","[爱心]":"ed04066ea7124106d17ffcaf75600700e5442f5c.png","[锦鲤]":"643d6c19c8164ffd89e3e9cdf093cf5d773d979c.png","[胜利]":"b49fa9f4b1e7c3477918153b82c60b114d87347c.png","[加油]":"c7aaeacb21e107292d3bb053e5abde4a4459ed30.png","[保佑]":"fafe8d3de0dc139ebe995491d2dac458a865fb30.png","[抱拳]":"89516218158dbea18ab78e8873060bf95d33bbbe.png","[响指]":"1b5c53cf14336903e1d2ae3527ca380a1256a077.png","[支持]":"3c210366a5585706c09d4c686a9d942b39feeb50.png","[拥抱]":"41780a4254750cdaaccb20735730a36044e98ef3.png","[怪我咯]":"07cc6077f7f7d75b8d2c722dd9d9828a9fb9e46d.png","[跪了]":"f2b3aee7e521de7799d4e3aa379b01be032698ac.png","[黑洞]":"e90ec4c799010f25391179118ccd9f66b3b279ba.png","[老鼠]":"8e6fb491eb1bb0d5862e7ec8ccf9a3da12b6c155.png","[2020]":"dc709fac0d361370bcf0d36d32adb97df7c95824.png","[福到了]":"5de5373d354c373cf1617b6b836f3a8d53c5a655.png"},
      enableQQ: false,
      path: window.location.pathname,
      requiredFields: ["nick,mail"],
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script src="//lib.baomitu.com/jquery/3.4.1/jquery.min.js"></script><script src="https://myhkw.cn/player/js/player.js" id="myhk" key="159721473362" m="1"></script><script src="https://cdn.jsdelivr.net/gh/stardust14/CDN/HexoStatic/js/Foster.js"></script><script src="https://cdn.jsdelivr.net/gh/stardust14/CDN/HexoStatic/js/hideCategory.min.js"></script><script src="https://cdn.jsdelivr.net/gh/stardust14/CDN/HexoStatic/js/title.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>